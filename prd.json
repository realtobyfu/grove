{
  "projectName": "Grove",
  "branchName": "v3/intelligence-layer",
  "description": "V3: LLM integration, reflection system, auto-tagging, connection suggestions, smart nudges, synthesis notes, and learning paths.",
  "userStories": [
    {
      "id": "S1",
      "title": "LLM Service Protocol & Groq Provider",
      "description": "Create the LLM service foundation with a protocol and Groq/Kimi K2 implementation.",
      "acceptanceCriteria": [
        "LLMProvider protocol in Services/LLM/LLMProvider.swift with func complete(system: String, user: String) async throws -> String",
        "GroqProvider.swift implements LLMProvider using URLSession to call https://api.groq.com/openai/v1/chat/completions",
        "Model is moonshotai/kimi-k2-instruct, OpenAI-compatible request format",
        "API key stored in UserDefaults or Keychain, configurable in settings",
        "Retry with exponential backoff (max 3 attempts)",
        "All calls are async and failure-tolerant — failures return nil, never crash",
        "LLMServiceConfig struct holds apiKey, model, baseURL, isEnabled toggle",
        "JSON response parsing helper that strips markdown fences and parses safely",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S2",
      "title": "LLM Settings UI",
      "description": "Add settings view for LLM configuration including API key, model selection, and usage tracking.",
      "acceptanceCriteria": [
        "Settings view accessible from sidebar or menu bar",
        "Section for AI/LLM with fields: API key (secure text field), model name, base URL",
        "Toggle to enable/disable AI features globally",
        "Token usage counter that tracks total input/output tokens used (stored in UserDefaults)",
        "Display estimated cost based on token count ($1.50/M blended)",
        "Reset usage counter button",
        "Settings persist across app launches",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S3",
      "title": "Auto-Tagging Service",
      "description": "Create AutoTagService that generates tags for captured items using the LLM.",
      "acceptanceCriteria": [
        "AutoTagService.swift in Services/ takes an Item and calls LLMProvider",
        "System prompt instructs LLM to return JSON with tags array (name, category, confidence) and one_line_summary",
        "Sends item title, sourceURL, and first 1500 characters of content",
        "Parses response into Tag entities with isAutoGenerated=true and confidence score",
        "Creates tags and associates them with the item via SwiftData",
        "Also sets a one-line summary on the item metadata",
        "Graceful failure — if LLM fails, item is saved without auto-tags",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S4",
      "title": "Wire Auto-Tagging into Capture Flow",
      "description": "Integrate AutoTagService into the existing capture/save flow so every new item gets auto-tagged.",
      "acceptanceCriteria": [
        "When a new Item is created (via quick capture or manual creation), AutoTagService.tagItem() is called",
        "Tagging runs as a background Task — does not block the UI or item creation",
        "Auto-generated tags appear on the item card with a visual distinction (dimmed or dashed border style)",
        "User can tap an auto-tag to confirm it (sets isAutoGenerated=false) or dismiss it (removes tag)",
        "If AI is disabled in settings, auto-tagging is skipped entirely",
        "Also generates suggested_board from LLM response and shows it in inbox triage",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S5",
      "title": "Reflection Data Model",
      "description": "Replace the Annotation model with a block-based Reflection model.",
      "acceptanceCriteria": [
        "New ReflectionBlock model replaces or extends Annotation",
        "Fields: id (UUID), item (Item relationship), blockType (enum: keyInsight, connection, question, disagreement, summary, freeform), content (String/markdown), highlight (String? — linked source text), position (Int for ordering), createdAt (Date)",
        "ReflectionBlockType enum with all six types and displayName computed property",
        "Item has a reflections relationship (one-to-many with ReflectionBlock)",
        "Migration or update from old Annotation model if needed — or keep both if Annotation data exists",
        "SwiftData model registered in the model container",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S6",
      "title": "Reflection Split View",
      "description": "Build the split-pane reflection view that shows source content on the left and reflection blocks on the right.",
      "acceptanceCriteria": [
        "When an item is opened, display a horizontal split view (HSplitView or similar)",
        "Left pane: article content, embedded web view, or note content (read-only)",
        "Right pane: list of ReflectionBlock entries for this item, plus an add button",
        "Each block shows its type as a subtle label (Key Insight, Question, etc.) and its markdown content",
        "Blocks are editable inline — click to edit, click away to save",
        "Add block button shows a picker for block type, then creates an empty block of that type",
        "If no reflections exist, show ghost text prompts: 'What is the key claim here?', 'How does this connect to what you know?', 'What would you challenge?'",
        "Text can be selected in the left pane — selecting text and clicking a 'Reflect' button creates a new block with that text as the highlight field",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S7",
      "title": "Reflection Block Editor",
      "description": "Polish the block editor with markdown support, wiki-links, and code blocks.",
      "acceptanceCriteria": [
        "Block content field is a markdown-aware text editor using swift-markdown and TextKit 2",
        "Typing [[ opens a fuzzy search dropdown of all items — selecting one inserts a wiki-link and auto-creates a Connection entity",
        "Code blocks render with syntax highlighting (at minimum Swift, Python, JavaScript)",
        "Basic markdown rendering: headings, bold, italic, inline code, links, bullet lists",
        "Each block has a subtle drag handle for reordering within the reflection",
        "Delete block with confirmation (or swipe/button)",
        "Block type can be changed after creation via a dropdown",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S8",
      "title": "Connection Suggestion Service",
      "description": "After saving or reflecting on an item, suggest related items to connect to.",
      "acceptanceCriteria": [
        "ConnectionSuggestionService.swift takes an Item and queries the LLM",
        "Sends the item's title, tags, and reflection content plus a list of up to 50 other items (title + tags only) from the same boards",
        "LLM returns JSON: array of {target_id, connection_type, reason}",
        "Service creates pending suggestion objects (not actual Connections yet)",
        "Suggestions shown in a collapsible section in the inspector panel",
        "Each suggestion shows target item title, connection type badge, and the AI's reason",
        "Accept creates the Connection entity with the reason as the note field",
        "Dismiss hides the suggestion — dismissed pairs are tracked and not re-suggested",
        "Only fires if AI is enabled and the item has content or reflections",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S9",
      "title": "AI Reflection Prompts",
      "description": "When opening the reflection view, generate contextual prompts based on the item and the user's existing knowledge.",
      "acceptanceCriteria": [
        "ReflectionPromptService.swift generates 2-3 prompts when the reflection view opens",
        "Sends to LLM: the current item (title, excerpt, tags) plus summaries of related items and existing reflections from same board",
        "LLM returns JSON array of prompts, each with a suggested block type and text",
        "Prompts reference the user's own items and reflections by name using [[wiki-link]] syntax",
        "Prompts appear as ghost-text placeholder blocks in the reflection pane",
        "Clicking a prompt block converts it to a real editable block with the prompt as starter text",
        "Dismissing a prompt hides it for that item",
        "Prompts only generate if the item has no existing reflections (don't overwrite user's work)",
        "Fires as a background task — reflection view is usable immediately, prompts appear when ready",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S10",
      "title": "Smart Nudge Engine",
      "description": "Replace basic time-based nudges with LLM-generated contextual nudges.",
      "acceptanceCriteria": [
        "SmartNudgeService.swift replaces or upgrades the existing NudgeEngine",
        "Fires on app launch (and optionally on a configurable timer)",
        "Sends to LLM: summary of boards (names, item counts), recent items (last 2 weeks with reflection status), engagement stats",
        "LLM returns one nudge as JSON: {type, message, target_item_id}",
        "Nudge types: reflection_prompt, contradiction, knowledge_gap, synthesis_prompt, course_continue",
        "Nudge displayed in the existing NudgeBar UI with action button and dismiss",
        "Acting on a nudge navigates to the relevant item or board",
        "Dismissed nudge types for specific items are tracked and not re-suggested",
        "Maximum one LLM nudge call per app launch",
        "Falls back to simple time-based nudges if AI is disabled",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S11",
      "title": "Engagement Score Overhaul",
      "description": "Redesign engagement scoring to weight reflections heavily, with a plant growth visual metaphor.",
      "acceptanceCriteria": [
        "New scoring: opened=5pts, manually_tagged=5pts, reflected=25pts, connected=15pts each, referenced_in_synthesis=20pts, revisited_after_7days=10pts",
        "Computed property on Item that calculates the score from relationships",
        "Score mapped to growth stages: seed (0-10), sprout (11-30), sapling (31-60), tree (61+)",
        "Visual indicator in ItemCardView and InspectorView uses SF Symbols or small custom icon for each stage",
        "Tooltip or label shows the breakdown on hover in the inspector",
        "Replace the old percentage bar engagement display everywhere it appears",
        "Board view can sort by engagement/depth score",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S12",
      "title": "Synthesis Note Generation",
      "description": "Allow users to generate an AI-drafted synthesis note from a board or tag cluster.",
      "acceptanceCriteria": [
        "SynthesisService.swift takes a scope (board or tag filter) and generates a synthesis draft",
        "Gathers all items + reflections in scope, sends titles, tags, one-line summaries, and reflection content to LLM",
        "System prompt: identify 3-5 themes, note contradictions, highlight user's own insights from reflections, list open questions, use [[wiki-links]]",
        "LLM response is parsed and created as a new Item with type .note",
        "Note is marked with metadata flag ai_generated=true",
        "UI: a 'Synthesize' button in board header and in tag cluster headers",
        "Generated note appears with a visible 'AI Draft' badge",
        "User can edit the note freely — editing removes the badge or changes it to 'Edited'",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S13",
      "title": "Weekly Digest",
      "description": "Generate a weekly summary of learning activity delivered as a nudge or inbox item.",
      "acceptanceCriteria": [
        "WeeklyDigestService.swift runs on app launch if 7+ days since last digest",
        "Gathers: items added this week, reflections written, connections formed, boards most active",
        "Sends summary to LLM to generate a short digest (150-250 words)",
        "Digest created as a special Item with type .note and metadata digest=true",
        "Includes: what was added (count + highlights), what was reflected on, knowledge gaps identified, suggested focus",
        "Configurable: can be disabled in settings, day of week can be changed",
        "Only generates if meaningful activity occurred (at least 2 items added or 1 reflection written)",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S14",
      "title": "Learning Path Generation",
      "description": "Generate ordered learning paths from saved items within a topic.",
      "acceptanceCriteria": [
        "LearningPathService.swift takes a topic (board or tag) and generates a sequenced path",
        "Sends all items in scope with their types, tags, engagement scores, and reflection status to LLM",
        "LLM returns JSON: ordered array of {item_id, reason, step_number} plus a final synthesis step",
        "LearningPath model: id, title, topic, steps (ordered array of LearningPathStep with item reference, reason, position)",
        "Learning path displayed as a special view — ordered list with progress indicators per item (not opened / read / reflected)",
        "Final step is always 'Write a synthesis note' with a button to trigger SynthesisService",
        "Path stored as a standalone entity associated with a Board",
        "User can reorder steps manually or regenerate",
        "Accessible via a 'Create learning path' button in board header",
        "Project builds successfully"
      ],
      "passes": false
    },
    {
      "id": "S15",
      "title": "Token Usage Tracking",
      "description": "Track and display LLM token usage across all services.",
      "acceptanceCriteria": [
        "TokenTracker singleton that records every LLM call: timestamp, service name, input tokens, output tokens, model",
        "GroqProvider parses usage from API response (usage.prompt_tokens, usage.completion_tokens) and reports to TokenTracker",
        "Token data persisted in UserDefaults or a lightweight store",
        "Settings UI shows: total tokens used, breakdown by service (tagging, suggestions, nudges, synthesis), estimated cost",
        "Reset button clears usage data",
        "Optional: monthly budget limit — when reached, AI features pause and user is notified",
        "Project builds successfully"
      ],
      "passes": false
    }
  ]
}
