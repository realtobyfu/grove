# Ralph Progress Log
Started: Tue Feb 17 12:22:39 HST 2026
---

## S1 — LLM Service Protocol & Groq Provider
**Status:** PASS
**Date:** 2026-02-17

**Files created:**
- `grove/Sources/LLMProvider.swift` — Protocol with `complete(system:user:)` returning `LLMCompletionResult?` (content + token counts)
- `grove/Sources/LLMServiceConfig.swift` — UserDefaults-backed config: apiKey, model (default: moonshotai/kimi-k2-instruct), baseURL (default: Groq endpoint), isEnabled toggle
- `grove/Sources/GroqProvider.swift` — Groq API implementation using URLSession, OpenAI-compatible format, exponential backoff (max 3 retries), retries on 429/5xx, returns nil on all failures
- `grove/Sources/LLMJSONParser.swift` — Safe JSON parsing: strips markdown fences, extracts balanced JSON objects/arrays, supports Decodable, dictionary, and array parsing

**Acceptance criteria:** All 9 met. Build passes with zero errors.

## S2 — LLM Settings UI
**Status:** PASS
**Date:** 2026-02-17

**Files modified:**
- `grove/Sources/AISettingsView.swift` — Rewrote to serve as LLM settings: global AI enable/disable toggle, Groq API key (SecureField), model name, base URL, configuration status indicator, token usage display (input/output/total with monospaced numbers), estimated cost ($1.50/M blended), reset usage button. Retains legacy Synthesis Provider section for backwards compatibility.
- `grove/Sources/LLMServiceConfig.swift` — Added token usage tracking: `totalInputTokens`, `totalOutputTokens`, `totalTokens`, `estimatedCost`, `recordUsage(inputTokens:outputTokens:)`, `resetUsage()`. All persisted in UserDefaults.
- `grove/Sources/GroqProvider.swift` — Wired `LLMServiceConfig.recordUsage()` into `parseResponse()` so every successful API call automatically tracks token usage.

**Acceptance criteria:** All 8 met. Settings accessible from Settings > AI tab. API key, model, base URL fields present. Global enable toggle. Token counter tracks input+output. Cost estimate at $1.50/M. Reset button clears counters. All settings persist via UserDefaults. Build passes with zero errors.

## S3 — Auto-Tagging Service
**Status:** PASS
**Date:** 2026-02-17

**Files created:**
- `grove/Sources/AutoTagService.swift` — `AutoTagServiceProtocol` (MainActor-isolated) and `AutoTagService` implementation. Takes an Item + ModelContext, sends title/sourceURL/first 1500 chars of content to LLM, parses JSON response into Tag entities with `isAutoGenerated=true` and confidence scores. Reuses existing tags by name. Sets `item.metadata["summary"]` from LLM's one-line summary. Graceful degradation — returns silently if AI disabled or LLM fails.

**Acceptance criteria:** All 8 met. AutoTagService in Sources/ takes Item and calls LLMProvider. System prompt returns JSON with tags (name, category, confidence) and one_line_summary. Sends title, sourceURL, first 1500 chars. Parses into Tag entities with isAutoGenerated=true. Associates tags with item via SwiftData. Sets one-line summary in metadata. Graceful failure on LLM error. Build passes with zero errors.

## S4 — Wire Auto-Tagging into Capture Flow
**Status:** PASS
**Date:** 2026-02-17

**Files modified:**
- `grove/Sources/AutoTagService.swift` — Updated LLM prompt to also return `suggested_board` (matching from user's existing boards). Added `suggested_board` field to `AutoTagResponse`. Stores result in `item.metadata["suggestedBoard"]`.
- `grove/Sources/ItemViewModel.swift` — Added `autoTagItem(itemID:context:)` private helper that checks `LLMServiceConfig.isConfigured` before running `AutoTagService.tagItem()`. Wired into `captureItem()` (fires after URL metadata fetch completes, or immediately for plain text notes) and `createVideoItem()` (fires after video metadata extraction). All calls run as background `Task` — does not block UI or item creation.
- `grove/Sources/InboxCard.swift` — Added `onConfirmTag`/`onDismissTag` callbacks. Auto-generated tags now render with dashed border (`StrokeStyle(dash: [3, 2])`) and dimmed text per DESIGN.md `border.tagDashed` token. Confirmed tags use solid border and primary text. Each auto-tag shows inline checkmark (confirm) and xmark (dismiss) buttons. Added suggested board display row. Uses `FlowLayout` (from ContentView) for wrapping tags. Typography updated to IBM Plex Mono/Sans per design system.
- `grove/Sources/InboxTriageView.swift` — Passes `onConfirmTag`/`onDismissTag` closures to `InboxCard`. Added `confirmTag()` (sets `isAutoGenerated=false`) and `dismissTag()` (removes tag from item). `keepItem()` now auto-assigns to suggested board if one matches an existing board name (case-insensitive), then still shows board picker for user to confirm or change.
- `grove/Sources/ItemCardView.swift` — Added tags row showing up to 3 tags with auto-generated visual distinction (dashed border + dimmed text vs solid border + primary text). Typography updated to IBM Plex Mono per design system.

**Acceptance criteria:** All 7 met.
1. When a new Item is created (via quick capture or video drop), `AutoTagService.tagItem()` is called — wired into `captureItem()` and `createVideoItem()`.
2. Tagging runs as a background Task — does not block UI or item creation.
3. Auto-generated tags appear with dashed border and dimmed text; confirmed tags have solid border and full opacity.
4. User can tap checkmark to confirm (sets `isAutoGenerated=false`) or xmark to dismiss (removes tag from item).
5. If AI is disabled in settings (`LLMServiceConfig.isConfigured` returns false), auto-tagging is skipped entirely.
6. `suggested_board` generated from LLM response, shown in inbox triage, and auto-assigned on Keep action.
7. Build passes with zero errors.

## S5 — Reflection Data Model
**Status:** PASS
**Date:** 2026-02-17

**Files created:**
- `grove/Sources/ReflectionBlock.swift` — `ReflectionBlockType` enum (String, Codable, CaseIterable) with six cases: keyInsight, connection, question, disagreement, summary, freeform. Each has `displayName` and `systemImage` computed properties. `@Model final class ReflectionBlock` with fields: id (UUID), item (Item? relationship), blockType (ReflectionBlockType), content (String/markdown), highlight (String? — linked source text), position (Int for ordering), createdAt (Date).

**Files modified:**
- `grove/Sources/Item.swift` — Added `@Relationship(deleteRule: .cascade, inverse: \ReflectionBlock.item) var reflections: [ReflectionBlock]` alongside existing annotations relationship. Initialized `self.reflections = []` in `init`.
- `grove/Sources/GroveApp.swift` — Added `ReflectionBlock.self` to the SwiftData `Schema([...])` array.

**Acceptance criteria:** All 7 met.
1. New ReflectionBlock model created — parallel to (not replacing) existing Annotation model, preserving any existing annotation data.
2. Fields: id (UUID), item (Item relationship), blockType (enum: keyInsight, connection, question, disagreement, summary, freeform), content (String/markdown), highlight (String? — linked source text), position (Int for ordering), createdAt (Date).
3. ReflectionBlockType enum with all six types and displayName computed property.
4. Item has a reflections relationship (one-to-many with ReflectionBlock, cascade delete).
5. Annotation model kept intact — both models coexist.
6. SwiftData model registered in the container (GroveApp.swift schema array).
7. Build passes with zero errors.

## S6 — Reflection Split View
**Status:** PASS
**Date:** 2026-02-17

**Files modified:**
- `grove/Sources/ItemReaderView.swift` — Complete overhaul from single-scroll layout to `HSplitView` split-pane reflection view.

**Architecture:**
- **Left pane (55%):** Source content (read-only). Article content uses new `SelectableMarkdownView` (NSTextView-backed `NSViewRepresentable`) for real text selection. Video items show `VideoPlayerView` + selectable content. Notes support edit mode via `WikiLinkTextEditor`. Legacy annotations section preserved below content.
- **Right pane (45%):** Reflection blocks list. Section header with "REFLECTIONS" label (IBM Plex Mono, uppercase, tracked) and count badge. Add Block button opens a 3-column grid picker for all 6 `ReflectionBlockType` values. Each block renders as a card with left-border accent, type icon + label, timestamp, content (markdown-rendered via `MarkdownTextView`), and ellipsis menu (edit, change type, delete).

**New components:**
- `SelectableMarkdownView` — `NSViewRepresentable` wrapping `NSTextView` (read-only, selectable). Renders markdown as `NSAttributedString` with Newsreader for headings, IBM Plex Sans for body, IBM Plex Mono for code blocks. Fires `onSelectText` callback on selection change, enabling the "Reflect on Selection" button.
- Ghost prompts — Three clickable placeholder rows shown when `item.reflections` is empty: "What is the key claim here?" (keyInsight), "How does this connect to what you know?" (connection), "What would you challenge?" (disagreement). Newsreader italic, text.muted color per DESIGN.md.
- Add block picker — 3x2 grid of all `ReflectionBlockType` cases with icon + display name. Creates empty block and auto-enters edit mode.
- Reflect from selection — When text is selected in `SelectableMarkdownView`, a "Reflect on Selection" button appears below the content. Clicking creates a new `keyInsight` block with the selected text as `highlight` field.
- Block inline editing — Clicking any block's content enters edit mode with `WikiLinkTextEditor`. Empty blocks show "Click to add your reflection..." ghost text. Save with Cmd+Return.
- Block type change — Via ellipsis menu, user can change any block's type after creation.

**Acceptance criteria:** All 8 met.
1. Item opens with horizontal split view (`HSplitView`) — left pane source content, right pane reflection blocks.
2. Left pane shows article content (rendered markdown via `SelectableMarkdownView`), video player, or note content (read-only or editable).
3. Right pane shows list of `ReflectionBlock` entries sorted by position, plus Add Block button.
4. Each block shows type label (icon + name), markdown content, and is editable inline (click to edit, save with Cmd+Return).
5. Add Block button shows picker for all 6 block types, creates empty block and enters edit mode.
6. Ghost text prompts shown when no reflections exist — three prompts matching spec text, clickable to create a block.
7. Text selection in left pane (via `NSTextView`) + "Reflect on Selection" button creates a new block with highlight field set.
8. Build passes with zero errors.

## S7 — Reflection Block Editor
**Status:** PASS
**Date:** 2026-02-17

**Files modified:**
- `grove/Sources/ItemReaderView.swift` — Major enhancements to reflection block editor:

**Features implemented:**
1. **Wiki-link [[  fuzzy search** — Already functional via `WikiLinkTextEditor` (used in block edit mode). Typing `[[` opens autocomplete dropdown of all items, selecting inserts `[[Item Title]]` and auto-creates a `.related` Connection entity.
2. **Syntax-highlighted code blocks** — New `SyntaxHighlightedCodeView` renders code blocks with language-aware token highlighting. Supports Swift, Python, and JavaScript with distinct colors for keywords (purple), types (green), strings (brown), comments (gray), numbers (blue), and builtins (teal). Language label shown above code in IBM Plex Mono uppercase.
3. **Markdown rendering** — `MarkdownTextView` now supports: headings (Newsreader font), bold, italic, inline code (via `AttributedString` markdown parsing), links, bullet lists (new `bulletList` block type with `•` prefix), wiki-links (rendered as blue underlined text), and code blocks with syntax highlighting. All fonts follow DESIGN.md tokens.
4. **Drag handles for reordering** — Each reflection block has a subtle drag handle (`line.3.horizontal` icon) on its left side. Blocks can be drag-and-dropped to reorder via `BlockDropDelegate` which updates `position` values and persists to SwiftData.
5. **Delete block with confirmation** — Deleting a block now shows a native `.alert` confirmation dialog ("Delete Reflection Block?") before proceeding, preventing accidental deletions.
6. **Block type changeable after creation** — Already functional from S6 via ellipsis menu > "Change Type" submenu listing all 6 `ReflectionBlockType` cases.

**New components:**
- `SyntaxHighlightedCodeView` — Token-based syntax highlighter for Swift, Python, JavaScript. Handles line/block comments, strings (single/double quote with escapes), numbers, keywords, type names, builtins, and decorators (@-prefixed). Monochromatic color palette consistent with DESIGN.md.
- `BlockDropDelegate` — `DropDelegate` implementation for drag-and-drop reordering of reflection blocks. Updates `position` fields on all blocks when reordered.

**Acceptance criteria:** All 7 met.
1. Block content field is a markdown-aware text editor using `WikiLinkTextEditor` (TextKit-based) for editing and `MarkdownTextView` for rendering.
2. Typing `[[` opens fuzzy search dropdown of all items — selecting inserts wiki-link and auto-creates Connection entity.
3. Code blocks render with syntax highlighting for Swift, Python, and JavaScript.
4. Basic markdown rendering: headings, bold, italic, inline code, links, bullet lists all supported.
5. Each block has a drag handle for reordering within the reflection pane.
6. Delete block shows confirmation dialog before deleting.
7. Block type can be changed after creation via ellipsis menu dropdown.
8. Build passes with zero errors.

## S8 — Connection Suggestion Service
**Status:** PASS
**Date:** 2026-02-17

**Files modified:**
- `grove/Sources/ConnectionSuggestionService.swift` — Major upgrade from heuristic-only to LLM-backed connection suggestions with heuristic fallback. Added `ConnectionSuggestionServiceProtocol` for testability. New `suggestConnectionsAsync(for:maxResults:)` async method sends item title, tags, content excerpt, and reflection content plus up to 50 candidate items (title + tags + summary) to LLM. System prompt instructs LLM to return JSON with `suggestions` array of `{target_title, connection_type, reason}`. Parses via `LLMJSONParser.decode`. Maps target titles back to Item objects. Falls back to existing heuristic `suggestConnections(for:)` if LLM is disabled, fails, or item has no content/reflections. Also enhanced heuristic keyword extraction to include reflection content. Dismissed pairs tracked in UserDefaults (unchanged).
- `grove/Sources/ConnectionSuggestionPopover.swift` — Restyled to match DESIGN.md monochromatic tokens. Replaced `.blue` accent with `Color(hex: "777777")`, `Color(hex: "1A1A1A")`, `Color(hex: "E8E8E8")`. Header uses IBM Plex Mono 10pt uppercase tracked. Body uses IBM Plex Sans-Regular. Connection type badge uses `accent.badge` (#E8E8E8) background with IBM Plex Mono 10pt semibold. Card background `#F7F7F7`, border `#EBEBEB`. Connect button uses monochromatic tint `#1A1A1A`.
- `grove/Sources/ItemReaderView.swift` — `triggerSuggestions()` now runs as async `Task {}` calling `suggestConnectionsAsync(for:)` for LLM-backed suggestions. `acceptSuggestion()` now sets `connection.note` to the LLM's reason string and `connection.isAutoGenerated = true` when creating the Connection entity.

**Acceptance criteria:** All 10 met.
1. `ConnectionSuggestionService.swift` takes an Item and queries the LLM — `suggestConnectionsAsync(for:)` sends item context to `LLMProvider.complete()`.
2. Sends item's title, tags, and reflection content plus a list of up to 50 other items (title + tags + summary) — built in `suggestWithLLM()` user prompt.
3. LLM returns JSON: array of `{target_title, connection_type, reason}` — parsed via `ConnectionSuggestionResponse` Decodable struct.
4. Service creates pending suggestion objects (not actual Connections yet) — returns `[ConnectionSuggestion]` structs, not persisted entities.
5. Suggestions shown in the connection suggestion popover overlay on ItemReaderView — `ConnectionSuggestionPopover` renders at `.topTrailing` of `HSplitView`.
6. Each suggestion shows target item title, connection type badge, and the AI's reason — all three visible in `suggestionRow()`.
7. Accept creates the Connection entity with the reason as the note field — `acceptSuggestion()` sets `connection.note = suggestion.reason`.
8. Dismiss hides the suggestion — dismissed pairs tracked in UserDefaults and not re-suggested via `dismissSuggestion()`.
9. Only fires if AI is enabled and the item has content or reflections — `suggestConnectionsAsync` checks `LLMServiceConfig.isConfigured` and `item.content != nil || !item.reflections.isEmpty`.
10. Build passes with zero errors.

## S9 — AI Reflection Prompts
**Status:** PASS
**Date:** 2026-02-17

**Files created:**
- `grove/Sources/ReflectionPromptService.swift` — `ReflectionPromptServiceProtocol` (MainActor-isolated) and `ReflectionPromptService` implementation. Takes an Item + ModelContext, sends item title, tags, content excerpt (first 1000 chars), related items from same boards (up to 10 with their reflections and summaries), and connected items (up to 5) to LLM. System prompt instructs LLM to return JSON with `prompts` array of `{block_type, text}`. Parses via `LLMJSONParser.decode`. Returns `[ReflectionPrompt]` structs (id, suggestedBlockType, text). Only generates if item has no existing reflections. Returns empty array on failure.

**Files modified:**
- `grove/Sources/ItemReaderView.swift` — Added AI prompt integration:
  - New state: `aiPrompts: [ReflectionPrompt]`, `isLoadingPrompts: Bool`, `dismissedPromptIDs: Set<UUID>`.
  - `loadAIPrompts()` fires on `.onAppear` and `.onChange(of: item.id)` as a background `Task`. Checks `item.reflections.isEmpty` and `LLMServiceConfig.isConfigured` before calling service.
  - Right pane now shows: (1) loading spinner while prompts generate, (2) AI prompt rows (dashed border, italic Newsreader text, block type icon) when available, (3) static ghost prompts as fallback when AI unavailable or loading complete with no results.
  - AI prompt rows: clicking a prompt creates a real editable block with the prompt text as starter content. Each prompt has an xmark dismiss button that hides it for that session.
  - State resets (prompts, dismissed IDs, loading flag) when item changes.

**Acceptance criteria:** All 10 met.
1. `ReflectionPromptService.swift` generates 2-3 prompts when the reflection view opens — `generatePrompts(for:in:)` called from `loadAIPrompts()` on view appear.
2. Sends to LLM: current item (title, excerpt, tags) plus summaries of related items and existing reflections from same board — built in user prompt with up to 10 board items and their reflections.
3. LLM returns JSON array of prompts, each with a suggested block type and text — parsed via `ReflectionPromptResponse` Decodable struct.
4. Prompts reference the user's own items and reflections by name using [[wiki-link]] syntax — system prompt explicitly instructs this.
5. Prompts appear as ghost-text placeholder blocks in the reflection pane — shown with dashed border, italic Newsreader font, muted color per DESIGN.md ghost text spec.
6. Clicking a prompt block converts it to a real editable block with the prompt as starter text — `onTapGesture` calls `createBlock(type:content:highlight:)` and auto-enters edit mode.
7. Dismissing a prompt hides it for that item — xmark button adds prompt ID to `dismissedPromptIDs` set, filtered out of visible prompts.
8. Prompts only generate if the item has no existing reflections — guarded by `item.reflections.isEmpty` check in both `loadAIPrompts()` and `generatePrompts()`.
9. Fires as a background task — reflection view is usable immediately, prompts appear when ready via `Task {}` with `withAnimation` on result.
10. Build passes with zero errors.

## S10 — Smart Nudge Engine
**Status:** PASS
**Date:** 2026-02-17

**Files created:**
- `grove/Sources/SmartNudgeService.swift` — `SmartNudgeServiceProtocol` (MainActor-isolated) and `SmartNudgeService` implementation. Takes a ModelContext, gathers board summaries (name, item count, reflected count), recent items (last 2 weeks with title, type, reflection status, tags, summary), and engagement stats (total items, reflected, connections, inbox count). Sends to LLM with system prompt instructing return of one nudge as JSON `{type, message, target_item_title}`. Parses via `LLMJSONParser.decode`. Maps LLM type strings to `NudgeType` enum. Resolves `target_item_title` to `UUID` by case-insensitive title match. Returns `SmartNudge` struct or nil on failure.

**Files modified:**
- `grove/Sources/Nudge.swift` — Added 5 new `NudgeType` cases for smart nudges: `reflectionPrompt`, `contradiction`, `knowledgeGap`, `synthesisPrompt`, `courseContinue`.
- `grove/Sources/NudgeEngine.swift` — Added `smartNudgeService: SmartNudgeServiceProtocol` dependency (injectable for testability, defaults to `SmartNudgeService()`). Added `hasGeneratedSmartNudgeThisLaunch` flag. New `generateSmartNudgeOnLaunch()` fires once on `startSchedule()` as background `Task`. Checks for pending/shown smart nudges, 30-day dismissal cooldown on type+target pairs. Falls back silently if AI disabled.
- `grove/Sources/NudgeBarView.swift` — Restyled to DESIGN.md monochromatic tokens: card background, border.primary border, border-radius 6px, IBM Plex Sans body text, IBM Plex Mono pill action button with accent.badge background, muted dismiss. Removed colored accent per-type. Smart nudge types navigate to target item on action.
- `grove/Sources/NudgeSettings.swift` — Added `isEnabled(for:)` cases for all 5 smart nudge types (enabled when `LLMServiceConfig.isConfigured`). Added `SmartDismissEntry` Codable struct and `recordSmartDismissal(type:itemID:)`/`isSmartNudgeDismissed(type:itemID:)` methods for 30-day dismissal tracking stored as JSON in UserDefaults.
- `grove/Sources/NudgeSettingsView.swift` — Added "Smart Nudges (AI)" section showing status based on `LLMServiceConfig.isConfigured`. Added analytics rows for all 5 smart nudge types.

**Acceptance criteria:** All 11 met.
1. `SmartNudgeService.swift` replaces/upgrades the existing NudgeEngine with LLM-backed nudges — `SmartNudgeService` integrated into `NudgeEngine` via protocol dependency.
2. Fires on app launch — `generateSmartNudgeOnLaunch()` called from `startSchedule()`.
3. Sends to LLM: summary of boards (names, item counts), recent items (last 2 weeks with reflection status), engagement stats — all built in `buildUserPrompt()`.
4. LLM returns one nudge as JSON: `{type, message, target_item_title}` — parsed via `SmartNudgeResponse` Decodable struct.
5. Nudge types: reflection_prompt, contradiction, knowledge_gap, synthesis_prompt, course_continue — all 5 mapped via `NudgeType` enum.
6. Nudge displayed in the existing NudgeBarView UI with action button and dismiss — restyled per DESIGN.md.
7. Acting on a nudge navigates to the relevant item — `onOpenItem?(item)` called for all smart nudge types with a target.
8. Dismissed nudge types for specific items are tracked and not re-suggested — 30-day cooldown via dismissal checks in both Nudge entities and NudgeSettings.
9. Maximum one LLM nudge call per app launch — `hasGeneratedSmartNudgeThisLaunch` flag prevents re-generation.
10. Falls back to simple time-based nudges if AI is disabled — `LLMServiceConfig.isConfigured` guard at top of `generateSmartNudgeOnLaunch()`.
11. Build passes with zero errors.

## S11 — Engagement Score Overhaul
**Status:** PASS
**Date:** 2026-02-17

**Files modified:**
- `grove/Sources/Item.swift` — Added `GrowthStage` enum (seed/sprout/sapling/tree) with `systemImage`, `iconSize`, `colorHex`/`darkColorHex` per DESIGN.md tokens, and `init(score:)` for score-to-stage mapping. Added computed properties on Item: `depthScore` (opened=5, manually_tagged=5, reflected=25 each, connected=15 each, referenced_in_synthesis=20, revisited_after_7days=10), `growthStage` (derived from depthScore), `scoreBreakdown` (array of label/points tuples for tooltip). Old `engagementScore: Float` stored property preserved for SwiftData backwards compatibility.
- `grove/Sources/ItemCardView.swift` — Added `GrowthStageIndicator` reusable view (SF Symbol icon sized per stage, color per DESIGN.md tokens, optional label). Added growth indicator to badges row with tooltip showing stage name and points. Replaced annotations badge with reflections count.
- `grove/Sources/ItemReaderView.swift` — Added `scoreBreakdownTooltip` computed property generating multi-line breakdown text. Added growth stage indicator with label and point count to item header metadata row, with `.help()` tooltip showing full breakdown.
- `grove/Sources/BoardDetailView.swift` — Renamed `BoardSortOption.engagementScore` to `.depthScore` ("Depth"). Sort now uses computed `depthScore` instead of stored `engagementScore`. Added `GrowthStageIndicator` to list row view. Replaced annotations badge with reflections count in list rows.
- `grove/Sources/GraphVisualizationView.swift` — Updated graph node sizing to use computed `depthScore` instead of stored `engagementScore`. Scaling normalized (score/6.0) since depth scores range higher than old 0-10 float.

**Acceptance criteria:** All 7 met.
1. New scoring: opened=5pts, manually_tagged=5pts, reflected=25pts each, connected=15pts each, referenced_in_synthesis=20pts, revisited_after_7days=10pts — all implemented as computed property `depthScore` on Item.
2. Computed property on Item calculates score from relationships — `depthScore` counts reflections, connections, tags, status, metadata, and engagement dates.
3. Score mapped to growth stages: seed (0-10), sprout (11-30), sapling (31-60), tree (61+) — via `GrowthStage(score:)` initializer.
4. Visual indicator in ItemCardView and ItemReaderView uses SF Symbols for each stage — `leaf` (seed), `leaf.fill` (sprout/sapling), `tree.fill` (tree) at increasing sizes per DESIGN.md spec.
5. Tooltip shows score breakdown on hover — `.help()` modifier on growth indicators in both ItemCardView, BoardDetailView list rows, and ItemReaderView header.
6. Old percentage bar engagement display replaced everywhere — graph nodes, sort options, card badges, and list rows all use `depthScore`/`GrowthStage` instead of `engagementScore`.
7. Board view can sort by depth score — `BoardSortOption.depthScore` sorts items descending by computed `depthScore`.
8. Build passes with zero errors.

## S12 — Synthesis Note Generation
**Status:** PASS
**Date:** 2026-02-17

**Files modified:**
- `grove/Sources/SynthesisService.swift` — Complete rewrite to use V3 LLM infrastructure. Removed legacy `SynthesisSettings`/`SynthesisProvider` types. Added `SynthesisServiceProtocol` for testability. New `generateLLMSynthesis()` sends item titles, tags, one-line summaries, content excerpts, and full reflection content to `GroqProvider`. System prompt instructs LLM to identify 3-5 themes, note contradictions, highlight user's own reflections (prioritized over source content), list open questions, and use [[wiki-link]] syntax. Falls back to local heuristic synthesis if LLM is disabled or fails. `createSynthesisItem()` now marks source items with `referencedInSynthesis=true` metadata for depth scoring. `SynthesisResult` uses `isLLMGenerated` boolean instead of provider enum.
- `grove/Sources/SynthesisSheet.swift` — Restyled to DESIGN.md monochromatic tokens. Replaced `.purple` accents with `Color(hex: "777777")`, `Color(hex: "E8E8E8")`. Headers use IBM Plex Mono 10pt uppercase tracked. Body uses IBM Plex Sans-Regular. Title field uses Newsreader 18pt. Shows "AI Draft" or "Local" provider badge. Indicates AI status in scope overview. Edit/Preview toggle uses monochromatic pill style.
- `grove/Sources/AISettingsView.swift` — Removed legacy Synthesis Provider section (picker, endpoint, API key, model fields). Replaced with unified Synthesis section showing AI/local status based on `LLMServiceConfig.isConfigured`. Synthesis now uses the same LLM configuration as all other V3 AI features.
- `grove/Sources/ItemCardView.swift` — Updated AI synthesis badge: shows "AI Draft" with sparkles icon when `isAIGenerated=true`, changes to "Edited" with pencil icon when `isAIEdited=true`. Uses IBM Plex Mono 10pt semibold, `Color(hex: "777777")` monochromatic style.
- `grove/Sources/ItemReaderView.swift` — Added AI Draft/Edited badge to item header for synthesis notes. When user finishes editing a synthesis note (clicks Done), automatically sets `isAIEdited=true` metadata.
- `grove/Sources/BoardDetailView.swift` — Added per-cluster Synthesize button in tag cluster headers (shown when cluster has 2+ items). Uses sparkles icon + "Synthesize" label in monochromatic pill. Opens `SynthesisSheet` scoped to that cluster's items. Added `showClusterSynthesisSheet` state and sheet presentation.

**Acceptance criteria:** All 8 met.
1. `SynthesisService.swift` takes a scope (board or tag filter) and generates a synthesis draft — `generateSynthesis(items:scopeTitle:)` accepts filtered items from board view or cluster.
2. Gathers all items + reflections in scope, sends titles, tags, one-line summaries, and reflection content to LLM — built in `generateLLMSynthesis()` user prompt with content excerpts, tags, summaries, and up to 5 reflections per item.
3. System prompt: identify 3-5 themes, note contradictions, highlight user's own insights from reflections, list open questions, use [[wiki-links]] — all specified in system prompt with explicit instructions.
4. LLM response is parsed and created as a new Item with type `.note` — `createSynthesisItem()` creates `Item(title:type:.note)` with `.active` status.
5. Note is marked with metadata flag `isAIGenerated=true` — set in `createSynthesisItem()`.
6. UI: a 'Synthesize' button in board header and in tag cluster headers — board header toolbar has `synthesisButton`, each cluster section header has conditional Synthesize pill button.
7. Generated note appears with a visible 'AI Draft' badge — shown in `ItemCardView` and `ItemReaderView` header when `isAIGenerated=true`.
8. User can edit the note freely — editing changes badge to 'Edited' via `isAIEdited=true` metadata set when user clicks Done in edit mode.
9. Build passes with zero errors.

## S13 — Weekly Digest
**Status:** PASS
**Date:** 2026-02-17

**Files created:**
- `grove/Sources/WeeklyDigestService.swift` — `WeeklyDigestServiceProtocol` (MainActor-isolated) and `WeeklyDigestService` implementation. Takes a ModelContext, gathers items added in last 7 days, reflections written, connections formed, and most active boards. Sends context to LLM with system prompt requesting a 150-250 word markdown digest covering: what was added, what was reflected on, knowledge gaps, and suggested focus. Uses [[wiki-link]] syntax for item references. Falls back to local heuristic digest if LLM is disabled or fails. Creates `Item(title: "Weekly Digest — {date}", type: .note)` with `metadata["digest"] = "true"`, `metadata["isAIGenerated"]`, and `metadata["digestDate"]`. Updates `NudgeSettings.digestLastGeneratedAt` on success.

**Files modified:**
- `grove/Sources/NudgeSettings.swift` — Added Weekly Digest settings: `digestEnabled` (Bool, default: true), `digestLastGeneratedAt` (TimeInterval, default: 0), `digestDayOfWeek` (Int, default: 2 = Monday). All stored in UserDefaults with `"digest.*"` keys.
- `grove/Sources/NudgeEngine.swift` — Added `weeklyDigestService: WeeklyDigestServiceProtocol` dependency (injectable for testability, defaults to `WeeklyDigestService()`). Added `hasCheckedDigestThisLaunch` flag. New `generateWeeklyDigestOnLaunch()` fires once from `startSchedule()` as background `Task`. Checks `NudgeSettings.digestEnabled` and 7+ day gap since last digest before calling service.
- `grove/Sources/NudgeSettingsView.swift` — Added "Weekly Digest" section with: enable/disable toggle, day-of-week picker (Sunday–Saturday), last generated status text (relative date or "No digest generated yet"), AI configuration status note.

**Acceptance criteria:** All 8 met.
1. `WeeklyDigestService.swift` runs on app launch if 7+ days since last digest — wired into `NudgeEngine.startSchedule()` via `generateWeeklyDigestOnLaunch()`.
2. Gathers: items added this week, reflections written, connections formed, boards most active — all fetched from SwiftData in `generateDigest()`.
3. Sends summary to LLM to generate a short digest (150-250 words) — system prompt instructs markdown format with four sections.
4. Digest created as a special Item with type `.note` and `metadata["digest"] = "true"` — created in `generateDigest()` with `.active` status.
5. Includes: what was added (count + highlights), what was reflected on, knowledge gaps identified, suggested focus — both LLM and local fallback cover all four areas.
6. Configurable: can be disabled in settings, day of week can be changed — `NudgeSettings.digestEnabled` toggle and `digestDayOfWeek` picker in `NudgeSettingsView`.
7. Only generates if meaningful activity occurred (at least 2 items added or 1 reflection written) — guarded by `newItems.count >= 2 || newReflections.count >= 1`.
8. Build passes with zero errors.

## S14 — Learning Path Generation
**Status:** PASS
**Date:** 2026-02-17

**Files created:**
- `grove/Sources/LearningPath.swift` — `LearningPathStepProgress` enum (notStarted/read/reflected) with `displayName` and `systemImage`. `@Model final class LearningPathStep` with fields: id (UUID), learningPath (LearningPath? relationship), item (Item? relationship), reason (String), position (Int), isSynthesisStep (Bool), progress (LearningPathStepProgress). `@Model final class LearningPath` with fields: id (UUID), title (String), topic (String), board (Board? relationship), createdAt (Date), updatedAt (Date), steps (cascade-delete relationship to LearningPathStep).
- `grove/Sources/LearningPathService.swift` — `LearningPathServiceProtocol` (MainActor-isolated) and `LearningPathService` implementation. Takes items, topic, board, and ModelContext. Sends item titles, types, tags, depth scores, reflection counts, connection counts, summaries, content excerpts, and reflection notes to LLM. System prompt instructs LLM to sequence items for optimal learning progression (foundational first, build complexity, group sub-topics). Parses JSON response with `steps` array of `{item_title, reason, step_number}` via `LLMJSONParser.decode`. Resolves titles to Item objects with case-insensitive matching. Auto-sets step progress from item state (reflected/read/notStarted). Appends final synthesis step. Falls back to heuristic ordering by depth score (ascending) if LLM disabled or fails.
- `grove/Sources/LearningPathView.swift` — `LearningPathSheet` (generation sheet) and `LearningPathDetailView` (full detail view). Sheet shows scope overview with items, growth indicators, AI status, then generates path with numbered timeline visualization. Detail view shows full path with progress bar (completed/total), numbered timeline with step cards, progress indicators per item (notStarted/read/reflected), growth stage indicators, tag display. Synthesis step has "Synthesize" button triggering `SynthesisSheet`. Step cards are clickable to navigate to items. All styled per DESIGN.md monochromatic tokens: IBM Plex Mono section headers, IBM Plex Sans body, Newsreader title, monochromatic colors, left-border selection accent on reflected items.

**Files modified:**
- `grove/Sources/GroveApp.swift` — Added `LearningPath.self` and `LearningPathStep.self` to SwiftData Schema array.
- `grove/Sources/BoardDetailView.swift` — Added `showLearningPathSheet` state. Added `learningPathButton` toolbar item with `list.number` icon (disabled when <2 items). Added `.sheet(isPresented: $showLearningPathSheet)` presenting `LearningPathSheet` scoped to board's filtered items.

**Acceptance criteria:** All 10 met.
1. `LearningPathService.swift` takes a topic (board) and generates a sequenced path — `generatePath(items:topic:board:in:)` accepts items and board context.
2. Sends all items in scope with their types, tags, engagement scores, and reflection status to LLM — built in `generateLLMPath()` user prompt with depth scores, reflection counts, connection counts, summaries, and excerpts.
3. LLM returns JSON: ordered array of `{item_title, reason, step_number}` plus a final synthesis step — parsed via `LearningPathResponse` Decodable struct, synthesis step appended programmatically.
4. `LearningPath` model: id, title, topic, steps (ordered array of `LearningPathStep` with item reference, reason, position) — both models created with all required fields.
5. Learning path displayed as a special view — `LearningPathDetailView` shows ordered list with numbered timeline, step cards, and progress indicators.
6. Progress indicators per item: not started (empty circle), read (half-filled circle), reflected (checkmark circle) — `LearningPathStepProgress` enum with three states, auto-set from item state.
7. Final step is always "Write a synthesis note" with a button to trigger `SynthesisService` — `isSynthesisStep=true` step with Synthesize button opening `SynthesisSheet`.
8. Path stored as a standalone entity associated with a Board — `LearningPath.board` optional relationship to Board.
9. Accessible via a "Create learning path" button in board header — `learningPathButton` in toolbar with `list.number` icon.
10. Build passes with zero errors.

## S15 — Token Usage Tracking
**Status:** PASS
**Date:** 2026-02-17

**Files created:**
- `grove/Sources/TokenTracker.swift` — `@MainActor` singleton that records every LLM call. `Entry` struct (Codable, Sendable) with fields: timestamp (Date), service (String), inputTokens (Int), outputTokens (Int), model (String). Persists entries as JSON in UserDefaults. Provides: `totalInputTokens`, `totalOutputTokens`, `totalTokens`, `estimatedCost` (at $1.50/M blended), `callCount`, `usageByService` (aggregated `ServiceUsage` structs sorted by total tokens descending), `currentMonthTokens` (filtered to current calendar month), `isBudgetExceeded` (checks `budgetEnabled` && `currentMonthTokens >= monthlyBudget`). Budget settings: `budgetEnabled` (Bool, default false), `monthlyBudget` (Int, default 1M tokens). `record(service:inputTokens:outputTokens:model:)` appends entry and also updates legacy `LLMServiceConfig` counters. `resetAll()` clears entries array and legacy counters.

**Files modified:**
- `grove/Sources/LLMProvider.swift` — Added `complete(system:user:service:)` method to protocol with default extension that delegates to `complete(system:user:)` for backwards compatibility.
- `grove/Sources/GroqProvider.swift` — Added `complete(system:user:service:)` implementation. Private `complete(system:user:serviceName:)` checks `TokenTracker.shared.isBudgetExceeded` before making API calls (returns nil if exceeded). `parseResponse(_:serviceName:)` reports to `TokenTracker.shared.record()` when service name is provided, falls back to legacy `LLMServiceConfig.recordUsage()` otherwise.
- `grove/Sources/AutoTagService.swift` — Updated `provider.complete()` call to pass `service: "tagging"`.
- `grove/Sources/ConnectionSuggestionService.swift` — Updated `provider.complete()` call to pass `service: "suggestions"`.
- `grove/Sources/ReflectionPromptService.swift` — Updated `provider.complete()` call to pass `service: "reflection_prompts"`.
- `grove/Sources/SmartNudgeService.swift` — Updated `provider.complete()` call to pass `service: "nudges"`.
- `grove/Sources/SynthesisService.swift` — Updated `provider.complete()` call to pass `service: "synthesis"`.
- `grove/Sources/WeeklyDigestService.swift` — Updated `provider.complete()` call to pass `service: "digest"`.
- `grove/Sources/LearningPathService.swift` — Updated `provider.complete()` call to pass `service: "learning_path"`.
- `grove/Sources/AISettingsView.swift` — Complete overhaul: reads from `TokenTracker.shared`. Shows input/output/total tokens with IBM Plex Mono. Estimated cost and API call count. "Usage by Service" section with all 7 services (tagging, suggestions, reflection_prompts, nudges, synthesis, digest, learning_path) with display names, per-service token counts and costs. "Monthly Budget" section: enable/disable toggle, configurable budget in thousands of tokens, current month usage vs budget, warning when exceeded. Reset clears all.

**Acceptance criteria:** All 7 met.
1. `TokenTracker` singleton records every LLM call: timestamp, service name, input tokens, output tokens, model — `Entry` struct with all fields, appended on every `record()` call.
2. `GroqProvider` parses usage from API response (`usage.prompt_tokens`, `usage.completion_tokens`) and reports to `TokenTracker` — `parseResponse(_:serviceName:)` extracts usage and calls `TokenTracker.shared.record()`.
3. Token data persisted in UserDefaults — entries stored as JSON via `JSONEncoder`/`JSONDecoder`, loaded on init.
4. Settings UI shows: total tokens used, breakdown by service (tagging, suggestions, nudges, synthesis, digest, reflection_prompts, learning_path), estimated cost — all displayed in "Token Usage" and "Usage by Service" sections.
5. Reset button clears usage data — `resetAll()` clears entries and legacy `LLMServiceConfig` counters.
6. Monthly budget limit — when `budgetEnabled`, `GroqProvider` checks `isBudgetExceeded` before every API call and returns nil. User notified via warning banner in settings.
7. Build passes with zero errors.
