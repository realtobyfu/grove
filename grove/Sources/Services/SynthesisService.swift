import Foundation
import SwiftData

/// Result of a synthesis generation.
struct SynthesisResult: Sendable {
    let markdownContent: String
    let sourceItemIDs: [UUID]
    let isLLMGenerated: Bool
}

/// Protocol for testability.
@MainActor
protocol SynthesisServiceProtocol {
    func generateSynthesis(items: [Item], scopeTitle: String) async -> SynthesisResult?
    func createSynthesisItem(from result: SynthesisResult, title: String, inBoard: Board?) -> Item
}

/// Service that generates AI synthesis notes from a collection of items.
/// Uses the V3 LLM infrastructure (GroqProvider) when configured, with local heuristic fallback.
@MainActor
@Observable
final class SynthesisService: SynthesisServiceProtocol {
    private let modelContext: ModelContext
    private let provider: LLMProvider
    var isGenerating = false
    var progress: String = ""
    var lastError: String?

    init(modelContext: ModelContext, provider: LLMProvider = LLMServiceConfig.makeProvider()) {
        self.modelContext = modelContext
        self.provider = provider
    }

    /// Validate whether synthesis can be performed on the given items.
    /// Returns nil if valid, or an error message if not.
    func validateScope(items: [Item]) -> String? {
        if items.isEmpty {
            return "No items to synthesize."
        }
        if items.count < AppConstants.Activity.synthesisMinItems {
            return "Need at least \(AppConstants.Activity.synthesisMinItems) items for synthesis."
        }
        if items.count > AppConstants.Activity.synthesisMaxItems {
            return "Too many items (\(items.count)). Synthesis works best with 3-15 items. Please narrow your scope."
        }
        return nil
    }

    /// Generate a synthesis note from the given items.
    /// Uses LLM when configured, falls back to local heuristic.
    func generateSynthesis(items: [Item], scopeTitle: String) async -> SynthesisResult? {
        guard EntitlementService.shared.canUse(.synthesis) else {
            lastError = "Synthesis requires Grove Pro."
            return nil
        }

        isGenerating = true
        progress = "Collecting content..."
        lastError = nil

        let result: SynthesisResult?

        if LLMServiceConfig.isConfigured {
            result = await generateLLMSynthesis(items: items, scopeTitle: scopeTitle)
        } else {
            result = await generateLocalSynthesis(items: items, scopeTitle: scopeTitle)
        }

        if result != nil {
            EntitlementService.shared.recordUse(.synthesis)
        }

        isGenerating = false
        progress = ""
        return result
    }

    /// Create a synthesis Item from the result, link it to source items via Connections.
    /// Marks source items with referencedInSynthesis metadata for depth scoring.
    func createSynthesisItem(from result: SynthesisResult, title: String, inBoard: Board?) -> Item {
        let item = Item(title: title, type: .note)
        item.status = .active
        item.content = result.markdownContent
        item.metadata["isAIGenerated"] = result.isLLMGenerated ? "true" : "false"
        item.metadata["synthesisDate"] = ISO8601DateFormatter().string(from: Date())
        item.metadata["sourceItemCount"] = "\(result.sourceItemIDs.count)"
        modelContext.insert(item)

        // Link to source items and mark them as referenced
        let descriptor = FetchDescriptor<Item>()
        let allItems = (try? modelContext.fetch(descriptor)) ?? []
        for sourceID in result.sourceItemIDs {
            if let sourceItem = allItems.first(where: { $0.id == sourceID }) {
                // Mark source item as referenced in synthesis (for depth scoring)
                sourceItem.metadata["referencedInSynthesis"] = "true"

                let connection = Connection(sourceItem: sourceItem, targetItem: item, type: .related)
                connection.isAutoGenerated = true
                connection.note = "Source for synthesis note"
                modelContext.insert(connection)
                sourceItem.outgoingConnections.append(connection)
                item.incomingConnections.append(connection)
            }
        }

        // Assign to board if provided
        if let board = inBoard, !board.isSmart {
            item.boards.append(board)
        }

        // Copy common tags from source items to synthesis note
        let sourceItems = allItems.filter { result.sourceItemIDs.contains($0.id) }
        let tagCounts = countTags(items: sourceItems)
        let commonTags = tagCounts.filter { $0.count >= AppConstants.Activity.commonTagThreshold }.sorted { $0.count > $1.count }.prefix(5)
        for (tag, _) in commonTags {
            if !item.tags.contains(where: { $0.id == tag.id }) {
                item.tags.append(tag)
            }
        }

        try? modelContext.save()
        return item
    }

    // MARK: - LLM Synthesis

    private func generateLLMSynthesis(items: [Item], scopeTitle: String) async -> SynthesisResult? {
        progress = "Preparing context for AI..."

        let systemPrompt = """
        You are a knowledge synthesis assistant. The user has collected items (articles, notes, videos, lectures) \
        and written personal reflections on them. Generate a synthesis note in markdown that:

        1. Identifies 3-5 key themes that emerge across the sources.
        2. Notes any contradictions or tensions between sources.
        3. Highlights the user's own insights from their reflection blocks — these are the most valuable part.
        4. Lists 2-3 open questions for further exploration.
        5. References specific items by title using [[Item Title]] wiki-link syntax.

        Rules:
        - Write in second person ("You noted...", "Your reflection on...").
        - Use markdown headings (##), bullet points, bold, and [[wiki-links]].
        - The synthesis should be 300-600 words.
        - Prioritize the user's own reflections over source content — this is a tool for thinking, not summarizing.
        - Structure: ## Key Themes, ## Contradictions, ## Your Insights, ## Open Questions
        - Only output the markdown content, no JSON wrapping.
        """

        // Build item descriptions with reflections
        let itemDescriptions = items.map {
            LLMContextBuilder.itemDescription($0, contentLimit: 500)
        }

        let userPrompt = """
        Synthesize the following \(items.count) items from the collection "\(scopeTitle)":

        \(itemDescriptions.enumerated().map { "--- Item \($0.offset + 1) ---\n\($0.element)" }.joined(separator: "\n\n"))

        Remember to use [[Item Title]] wiki-link syntax when referencing items, and prioritize the user's own reflections.
        """

        progress = "Generating synthesis..."

        guard let result = await provider.complete(system: systemPrompt, user: userPrompt, service: "synthesis") else {
            // Fall back to local synthesis on LLM failure
            progress = "AI unavailable, falling back to local synthesis..."
            return await generateLocalSynthesis(items: items, scopeTitle: scopeTitle)
        }

        let markdown = result.content.trimmingCharacters(in: .whitespacesAndNewlines)

        guard !markdown.isEmpty else {
            return await generateLocalSynthesis(items: items, scopeTitle: scopeTitle)
        }

        return SynthesisResult(
            markdownContent: markdown,
            sourceItemIDs: items.map(\.id),
            isLLMGenerated: true
        )
    }

    // MARK: - Local Synthesis (Heuristic Fallback)

    private func generateLocalSynthesis(items: [Item], scopeTitle: String) async -> SynthesisResult? {
        progress = "Analyzing \(items.count) items..."

        let itemSummaries = items.map { item -> (item: Item, keywords: Set<String>) in
            let text = [item.title, item.content ?? ""].joined(separator: " ")
            let keywords = extractKeywords(from: text)
            return (item, keywords)
        }

        progress = "Finding themes..."

        var keywordFrequency: [String: Int] = [:]
        for summary in itemSummaries {
            for keyword in summary.keywords {
                keywordFrequency[keyword, default: 0] += 1
            }
        }
        let themes = keywordFrequency
            .filter { $0.value >= 2 }
            .sorted { $0.value > $1.value }
            .prefix(5)
            .map { $0.key }

        let tagCounts = countTags(items: items)
        let commonTags = tagCounts.filter { $0.count >= AppConstants.Activity.commonTagThreshold }.sorted { $0.count > $1.count }

        progress = "Generating synthesis..."

        var md = "## Key Themes\n\n"
        if themes.isEmpty {
            md += "No strong recurring themes detected across these items.\n\n"
        } else {
            for theme in themes {
                let relatedItems = itemSummaries.filter { $0.keywords.contains(theme) }
                let itemTitles = relatedItems.prefix(3).map { "[[\($0.item.title)]]" }.joined(separator: ", ")
                md += "- **\(theme.capitalized)** — appears across \(relatedItems.count) items: \(itemTitles)\n"
            }
            md += "\n"
        }

        if !commonTags.isEmpty {
            md += "## Shared Topics\n\n"
            for (tag, count) in commonTags.prefix(5) {
                md += "- **\(tag.name)** — \(count) items\n"
            }
            md += "\n"
        }

        // User reflections
        let reflectedItems = items.filter { !$0.reflections.isEmpty }
        if !reflectedItems.isEmpty {
            md += "## Your Insights\n\n"
            for item in reflectedItems {
                md += "From [[\(item.title)]]:\n"
                for block in item.reflections.sorted(by: { $0.position < $1.position }).prefix(3) {
                    md += "- *\(block.blockType.displayName):* \(String(block.content.prefix(150)))\n"
                }
                md += "\n"
            }
        }

        // Sources
        md += "## Sources\n\n"
        for item in items.sorted(by: { $0.createdAt < $1.createdAt }) {
            md += "- [[\(item.title)]]"
            if !item.tags.isEmpty {
                md += " (\(item.tags.prefix(3).map(\.name).joined(separator: ", ")))"
            }
            md += "\n"
        }
        md += "\n"

        md += "## Open Questions\n\n"
        md += "- What are the practical implications of these combined insights?\n"
        md += "- Are there tensions between these sources not yet explored?\n"
        md += "- What related topics should be investigated next?\n"

        return SynthesisResult(
            markdownContent: md,
            sourceItemIDs: items.map(\.id),
            isLLMGenerated: false
        )
    }

    // MARK: - Helpers

    private func extractKeywords(from text: String) -> Set<String> {
        TextTokenizer.extractKeywords(from: text)
    }

    private func countTags(items: [Item]) -> [(tag: Tag, count: Int)] {
        var counts: [UUID: (tag: Tag, count: Int)] = [:]
        for item in items {
            for tag in item.tags {
                if let existing = counts[tag.id] {
                    counts[tag.id] = (existing.tag, existing.count + 1)
                } else {
                    counts[tag.id] = (tag, 1)
                }
            }
        }
        return counts.values.map { ($0.tag, $0.count) }
    }
}
